I’ve been thinking about how to sharpen the piece so that it speaks more to the dilemma of increased connectivity within groups/villages, but decreased communication between groups.  This can have a dehumanizing effect on the perception of outsiders.  Of course this has always been happening throughout history, but maybe the technology has increased the ability of groups to close in on themselves.  Perhaps this could be symbolized by having the faces on the globe take turns putting words out there and when one is talking the other face becomes mutated or masked, or made more robotic.  The technology for manipulating face images can be fairly simple, and is something I have played with in previous installations (for example, making people’s eyes bulge out by identifying the eyes is the haar face detector, copy them and just paste them over the face after scaling them gradually bigger; it is also easy to make the chin drop and mouth gap open).

It would be interesting to do some semantic analysis (e.g. LSA) of different forums or Google+ group conversations to identify the key focal points in semantic space.  For this installation, I would use an existing LSA bag-of-words semantic space to determine which words should stick together and grow other related words, and which words should conflict with each other, maybe bounce off or turn red and angry.  There are also psycholinguistic databases that I’ve used at work that have ratings for the emotional content and intensity of individual words.  If the participant says one word and then pauses, a bunch of suggested words could appear (semi-transparently) based on nearby words in different forum conversations.  Identification of the participant with a specific forum or viewpoint could be used to trigger the video face and words of previous participants in the same or opposing groups.

Implementation details:

The simplest implementation would be a wall sized flat projection.  Since there is a fair amount of software to write (or piece together from things I’ve done before), this might be the best option.   To make it a little more interesting, the flat wall/screen could have a convex half-sphere sticking out that the globe would be projected on.  A little more experimental (and I’d have to do a small scale of this first) would be to use a concave half-sphere to give the illusion of 3D as you walk around it.  This is a classic illusion for inverse faces (just look in the back of a face mask with the right lighting and it seems to flip to convex and follow you around).  If you wanted to really go for it, there are commercially available spherical displays, but they are custom and expensive.  I would not want to build my own because that would take most of the time available, and may not look so great since physical implementation is not my strongest suit.  The idea of using multiple projectors on a cylindrical screen sounded good, but when I started to think it through I realized it would be difficult to make it look right.

The other components are pretty much off the shelf.  I like the Sony or Panasonic video cameras and the Osprey frame capture cards.  I always build my own PC to get the performance I need.  I usually use Linux and C++/C wrapped with shell scripts and perl.  I like the openCV library a lot because it is fast, has lots of algorithms, is pretty well used and debugged, and you can go to low level pixel manipulation easily and efficiently if needed.  I use Nvidia graphics cards because they have historically had better driver support.

For the speech recognition, image search, youtube videos, I may need to some help to get the sort of access that would make things easy.  I have in the past made “robot” web accesses to do these things, being careful to limit the bandwidth.  

